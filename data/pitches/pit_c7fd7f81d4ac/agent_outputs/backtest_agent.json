{
  "status": "success",
  "metrics": {
    "backtest_start": "2021-06-16",
    "backtest_end": "2026-02-20",
    "cagr": 0.036215,
    "total_return": 0.180592,
    "volatility": 0.085352,
    "sharpe_ratio": -0.009076,
    "sortino_ratio": -0.007878,
    "calmar_ratio": 0.230654,
    "max_drawdown": -0.157011,
    "max_drawdown_duration": 931,
    "total_trades": 8,
    "win_rate": 0.375,
    "avg_win": 0.078012,
    "avg_loss": -0.013296,
    "profit_factor": 3.520291,
    "expectancy": 0.020944,
    "benchmark_cagr": 0.125261,
    "benchmark_max_drawdown": -0.24512,
    "benchmark_total_return": 0.734528,
    "alpha": -0.025191,
    "information_ratio": -0.633039,
    "excess_return": -0.089045,
    "up_capture": 0.347858,
    "down_capture": 0.355546,
    "name": "pit_c7fd7f81d4ac",
    "ticker": "SPY"
  },
  "message": "Backtest completed successfully on attempt 1.",
  "attempt_count": 1,
  "attempt_history": [
    {
      "attempt": 1,
      "phase_reached": "review",
      "script": "import subprocess, sys\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numpy\", \"pandas\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n\nimport os\nimport io\nimport json\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\n\n# \u2500\u2500 Verbatim Alpaca fetch function \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef _fetch_benchmark_alpaca(\n    ticker: str,\n    start: str,\n    end: str,\n    timeframe: str = \"1Day\",\n    adjustment: str = \"all\",\n    feed: str = \"sip\",\n    limit: int = 10000,\n    sort: str = \"asc\",\n) -> \"pd.DataFrame\":\n    import os, json, urllib.request, urllib.parse, urllib.error, re\n    api_key = os.getenv(\"ALPACA_API_KEY\", \"\")\n    api_secret = os.getenv(\"ALPACA_API_SECRET\", \"\")\n    if not api_key or not api_secret:\n        raise RuntimeError(\"ALPACA_API_KEY or ALPACA_API_SECRET environment variable is not set.\")\n\n    timeframe = str(timeframe or \"1Day\").strip()\n    if not re.match(r\"^[1-9][0-9]*(Min|Hour|Day|Week|Month)$\", timeframe):\n        raise RuntimeError(\n            f\"Invalid Alpaca timeframe '{timeframe}'. \"\n            \"Expected values like 1Min, 5Min, 15Min, 1Hour, 1Day.\"\n        )\n    adjustment = str(adjustment or \"all\").strip().lower()\n    if adjustment not in {\"raw\", \"split\", \"dividend\", \"all\"}:\n        raise RuntimeError(f\"Invalid Alpaca adjustment '{adjustment}'.\")\n    feed = str(feed or \"sip\").strip().lower()\n    if feed not in {\"sip\", \"iex\", \"otc\"}:\n        raise RuntimeError(f\"Invalid Alpaca feed '{feed}'.\")\n    sort = str(sort or \"asc\").strip().lower()\n    if sort not in {\"asc\", \"desc\"}:\n        raise RuntimeError(f\"Invalid Alpaca sort '{sort}'.\")\n    try:\n        limit = max(1, min(10000, int(limit)))\n    except Exception as exc:\n        raise RuntimeError(f\"Invalid Alpaca limit '{limit}'.\") from exc\n\n    base_url = \"https://data.alpaca.markets/v2/stocks/bars\"\n    headers = {\n        \"APCA-API-KEY-ID\": api_key,\n        \"APCA-API-SECRET-KEY\": api_secret,\n        \"Accept\": \"application/json\",\n    }\n    bars = []\n    feed_candidates = [feed] if feed != \"sip\" else [\"sip\", \"iex\"]\n    last_http_error = None\n    chosen_feed = None\n    for feed_candidate in feed_candidates:\n        bars = []\n        page_token = None\n        request_failed = False\n        while True:\n            params = {\n                \"symbols\": ticker,\n                \"timeframe\": timeframe,\n                \"start\": start,\n                \"end\": end,\n                \"adjustment\": adjustment,\n                \"feed\": feed_candidate,\n                \"limit\": str(limit),\n                \"sort\": sort,\n            }\n            if page_token:\n                params[\"page_token\"] = page_token\n            url = base_url + \"?\" + urllib.parse.urlencode(params)\n            req = urllib.request.Request(url, headers=headers)\n            try:\n                with urllib.request.urlopen(req, timeout=30) as resp:\n                    data = json.loads(resp.read().decode())\n            except urllib.error.HTTPError as exc:\n                request_failed = True\n                last_http_error = (exc.code, exc.reason, feed_candidate)\n                break\n            except urllib.error.URLError as exc:\n                raise RuntimeError(f\"Alpaca API network error: {exc.reason}\") from exc\n\n            symbol_bars = data.get(\"bars\", {}).get(ticker.upper(), [])\n            bars.extend(symbol_bars)\n            page_token = data.get(\"next_page_token\")\n            if not page_token:\n                break\n\n        if not request_failed and bars:\n            chosen_feed = feed_candidate\n            break\n\n    if not bars:\n        if last_http_error is not None:\n            code, reason, failing_feed = last_http_error\n            raise RuntimeError(\n                f\"Alpaca API HTTP error {code}: {reason} (feed={failing_feed}, tried={feed_candidates})\"\n            )\n        raise RuntimeError(\n            f\"Alpaca returned 0 bars for {ticker} between {start} and {end}. \"\n            \"Check that the ticker is valid and the date range covers trading days.\"\n        )\n\n    import pandas as pd\n    df = pd.DataFrame(bars)\n    df[\"date\"] = pd.to_datetime(df.get(\"t\"), errors=\"coerce\", utc=True).dt.tz_localize(None)\n    df[\"open\"] = pd.to_numeric(df.get(\"o\"), errors=\"coerce\")\n    df[\"high\"] = pd.to_numeric(df.get(\"h\"), errors=\"coerce\")\n    df[\"low\"] = pd.to_numeric(df.get(\"l\"), errors=\"coerce\")\n    df[\"close\"] = pd.to_numeric(df.get(\"c\"), errors=\"coerce\")\n    df[\"volume\"] = pd.to_numeric(df.get(\"v\"), errors=\"coerce\")\n    df[\"vwap\"] = pd.to_numeric(df.get(\"vw\"), errors=\"coerce\")\n    df[\"trade_count\"] = pd.to_numeric(df.get(\"n\"), errors=\"coerce\")\n    df = (\n        df[[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"vwap\", \"trade_count\"]]\n        .dropna(subset=[\"date\", \"close\"])\n        .drop_duplicates(subset=[\"date\"])\n        .sort_values(\"date\")\n        .reset_index(drop=True)\n    )\n    if df.empty:\n        raise RuntimeError(f\"Alpaca bars for {ticker} contained no parseable close prices.\")\n\n    df[\"Open\"] = df[\"open\"]\n    df[\"High\"] = df[\"high\"]\n    df[\"Low\"] = df[\"low\"]\n    df[\"Close\"] = df[\"close\"]\n    df[\"Volume\"] = df[\"volume\"]\n    df[\"Adj Close\"] = df[\"close\"]\n    df[\"alpaca_feed\"] = chosen_feed or feed\n    return df\n\n\n# \u2500\u2500 Parameters (mirrors strategy) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nTICKER = \"SPY\"\nSTART_DATE = \"2005-01-01\"\nEND_DATE = datetime.today().strftime(\"%Y-%m-%d\")\nTREND_WINDOW = 200\nYIELD_SPREAD_THRESHOLD = -0.10\nYIELD_SPREAD_SMOOTHING = 20\nTRANSACTION_COST = 0.0005\n\nprint(f\"Fetching price data for {TICKER} from Alpaca...\", file=sys.stderr)\n\n# Fetch price data via Alpaca (canonical dataset)\nprice_df = _fetch_benchmark_alpaca(\n    ticker=TICKER,\n    start=START_DATE,\n    end=END_DATE,\n    timeframe=\"1Day\",\n    adjustment=\"all\",\n    feed=\"sip\",\n    limit=10000,\n    sort=\"asc\",\n)\n\nprint(f\"ALPACA_FETCH_OK timeframe=1Day rows={len(price_df)}\", file=sys.stderr)\n\n# Persist canonical dataset\nprice_df.to_csv(\"__internal_price_data.csv\", index=False)\nprint(f\"Saved canonical price data to __internal_price_data.csv ({len(price_df)} rows)\", file=sys.stderr)\n\n# Set date as index for strategy logic\nprices = price_df.set_index(\"date\")[[\"close\"]].copy()\nprices.index = pd.to_datetime(prices.index)\nprices.sort_index(inplace=True)\n\n# \u2500\u2500 Load yield curve data \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nprint(\"Loading yield curve data from T10Y2Y_spread.csv...\", file=sys.stderr)\nyc_path = \"T10Y2Y_spread.csv\"\nif os.path.exists(yc_path):\n    yc_df = pd.read_csv(yc_path, parse_dates=[\"observation_date\"], index_col=\"observation_date\")\n    yc_df.columns = [\"spread\"]\n    yc_df[\"spread\"] = pd.to_numeric(yc_df[\"spread\"], errors=\"coerce\")\n    yc_df.sort_index(inplace=True)\n    spread = yc_df[\"spread\"].dropna()\n    print(f\"  Loaded {len(spread)} FRED observations from local file.\", file=sys.stderr)\nelse:\n    # Fallback: try to fetch from FRED\n    print(\"  Local T10Y2Y_spread.csv not found, fetching from FRED...\", file=sys.stderr)\n    try:\n        import urllib.request\n        fred_url = \"https://fred.stlouisfed.org/graph/fredgraph.csv?id=T10Y2Y\"\n        with urllib.request.urlopen(fred_url, timeout=15) as resp:\n            fred_text = resp.read().decode()\n        yc_df = pd.read_csv(io.StringIO(fred_text), parse_dates=[\"observation_date\"], index_col=\"observation_date\")\n        yc_df.columns = [\"spread\"]\n        yc_df[\"spread\"] = pd.to_numeric(yc_df[\"spread\"], errors=\"coerce\")\n        yc_df.sort_index(inplace=True)\n        spread = yc_df[\"spread\"].dropna()\n        print(f\"  Fetched {len(spread)} FRED observations.\", file=sys.stderr)\n    except Exception as e:\n        print(f\"  Could not fetch FRED data: {e}. Using zero spread (all dates OK).\", file=sys.stderr)\n        spread = pd.Series(0.0, index=prices.index, name=\"spread\")\n\n# Filter spread to backtest range\nspread = spread.loc[START_DATE:END_DATE]\n\n# \u2500\u2500 Build signals \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndf = prices.copy()\ndf[\"sma200\"] = df[\"close\"].rolling(TREND_WINDOW).mean()\ndf[\"above_trend\"] = (df[\"close\"] > df[\"sma200\"]).astype(int)\n\nspread_ff = spread.reindex(df.index, method=\"ffill\")\ndf[\"spread\"] = spread_ff\ndf[\"spread_smooth\"] = spread_ff.rolling(YIELD_SPREAD_SMOOTHING).mean()\ndf[\"curve_ok\"] = (df[\"spread_smooth\"] > YIELD_SPREAD_THRESHOLD).astype(int)\ndf[\"signal\"] = df[\"above_trend\"] * df[\"curve_ok\"]\n\n# \u2500\u2500 Run backtest \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndf[\"daily_ret\"] = df[\"close\"].pct_change()\ndf[\"position\"] = df[\"signal\"].shift(1).fillna(0)\ndf[\"trades\"] = df[\"position\"].diff().abs().fillna(0)\ndf[\"strat_ret\"] = df[\"position\"] * df[\"daily_ret\"] - df[\"trades\"] * TRANSACTION_COST\ndf[\"bm_ret\"] = df[\"daily_ret\"].fillna(0)\n\n# Drop warm-up\nwarmup = TREND_WINDOW + YIELD_SPREAD_SMOOTHING + 5\ndf = df.iloc[warmup:].copy()\ndf = df.dropna(subset=[\"strat_ret\", \"bm_ret\"])\n\nprint(f\"Backtest period: {df.index[0].date()} \u2192 {df.index[-1].date()} ({len(df)} days)\", file=sys.stderr)\n\n# Equity curves\ndf[\"equity\"] = (1 + df[\"strat_ret\"]).cumprod()\ndf[\"bm_equity\"] = (1 + df[\"bm_ret\"]).cumprod()\n\nbacktest_start = str(df.index[0].date())\nbacktest_end = str(df.index[-1].date())\nn_years = len(df) / 252.0\n\n# \u2500\u2500 Core metrics \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntotal_return = float(df[\"equity\"].iloc[-1] - 1)\nbm_total_return = float(df[\"bm_equity\"].iloc[-1] - 1)\n\ncagr = float(df[\"equity\"].iloc[-1] ** (1.0 / n_years) - 1) if n_years > 0 else 0.0\nbm_cagr = float(df[\"bm_equity\"].iloc[-1] ** (1.0 / n_years) - 1) if n_years > 0 else 0.0\n\nvol = float(df[\"strat_ret\"].std() * np.sqrt(252))\n\nrf_daily = 0.04 / 252.0\nexcess_daily = df[\"strat_ret\"] - rf_daily\nsharpe = float(excess_daily.mean() / (excess_daily.std() + 1e-10) * np.sqrt(252))\n\nneg_rets = df[\"strat_ret\"][df[\"strat_ret\"] < 0]\nsortino_denom = float(neg_rets.std() * np.sqrt(252)) if len(neg_rets) > 1 else 1e-10\nsortino = float((df[\"strat_ret\"].mean() * 252 - 0.04) / (sortino_denom + 1e-10))\n\n# Max drawdown \u2013 strategy\nrolling_max = df[\"equity\"].cummax()\ndrawdown = df[\"equity\"] / rolling_max - 1\nmax_dd = float(drawdown.min())\n\n# Max drawdown duration\nin_dd = (drawdown < 0)\ndd_duration = 0\nmax_dd_duration = 0\nfor val in in_dd:\n    if val:\n        dd_duration += 1\n        max_dd_duration = max(max_dd_duration, dd_duration)\n    else:\n        dd_duration = 0\n\ncalmar = float(cagr / abs(max_dd)) if max_dd != 0 else 0.0\n\n# Benchmark max drawdown\nbm_rolling_max = df[\"bm_equity\"].cummax()\nbm_drawdown = df[\"bm_equity\"] / bm_rolling_max - 1\nbm_max_dd = float(bm_drawdown.min())\n\n# \u2500\u2500 Trade statistics \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntrade_returns = []\nin_trade = False\nentry_eq = 1.0\nfor _, row in df.iterrows():\n    if row[\"position\"] == 1 and not in_trade:\n        in_trade = True\n        entry_eq = row[\"equity\"]\n    elif row[\"position\"] == 0 and in_trade:\n        in_trade = False\n        trade_returns.append(float(row[\"equity\"] / entry_eq - 1))\n\n# Close any open trade at end\nif in_trade:\n    trade_returns.append(float(df[\"equity\"].iloc[-1] / entry_eq - 1))\n\ntotal_trades = len(trade_returns)\nwins = [r for r in trade_returns if r > 0]\nlosses = [r for r in trade_returns if r <= 0]\n\nwin_rate = float(len(wins) / total_trades) if total_trades > 0 else 0.0\navg_win = float(np.mean(wins)) if wins else 0.0\navg_loss = float(np.mean(losses)) if losses else 0.0\n\nsum_wins = sum(wins)\nsum_losses = abs(sum(losses))\nprofit_factor = float(sum_wins / sum_losses) if sum_losses > 0 else float(sum_wins > 0) * 9999.0\n\nexpectancy = win_rate * avg_win + (1 - win_rate) * avg_loss\n\n# \u2500\u2500 Alpha / IR / Capture \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nstrat_r = df[\"strat_ret\"].fillna(0).values\nbm_r = df[\"bm_ret\"].fillna(0).values\n\ncov_matrix = np.cov(strat_r, bm_r)\nbeta = float(cov_matrix[0, 1] / (cov_matrix[1, 1] + 1e-10))\nalpha = float(cagr - (0.04 + beta * (bm_cagr - 0.04)))\n\nexcess_vs_bm = df[\"strat_ret\"] - df[\"bm_ret\"]\ninformation_ratio = float(excess_vs_bm.mean() / (excess_vs_bm.std() + 1e-10) * np.sqrt(252))\nexcess_return = cagr - bm_cagr\n\nup_days = df[df[\"bm_ret\"] > 0]\ndown_days = df[df[\"bm_ret\"] < 0]\nup_capture = (\n    float(up_days[\"strat_ret\"].mean() / up_days[\"bm_ret\"].mean())\n    if len(up_days) > 0 and up_days[\"bm_ret\"].mean() != 0 else 0.0\n)\ndown_capture = (\n    float(down_days[\"strat_ret\"].mean() / down_days[\"bm_ret\"].mean())\n    if len(down_days) > 0 and down_days[\"bm_ret\"].mean() != 0 else 0.0\n)\n\n# \u2500\u2500 Fetch benchmark data (separate call as required) \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nprint(\"Fetching benchmark (buy-and-hold SPY) from Alpaca...\", file=sys.stderr)\nbench_df = _fetch_benchmark_alpaca(\n    ticker=TICKER,\n    start=backtest_start,\n    end=backtest_end,\n    timeframe=\"1Day\",\n    adjustment=\"all\",\n    feed=\"sip\",\n    limit=10000,\n    sort=\"asc\",\n)\nprint(f\"ALPACA_FETCH_OK timeframe=1Day rows={len(bench_df)}\", file=sys.stderr)\n\nbench_close = bench_df.set_index(\"date\")[\"close\"].sort_index()\nbench_ret = bench_close.pct_change().dropna()\nbench_eq = (1 + bench_ret).cumprod()\nbench_n_years = len(bench_ret) / 252.0\nbench_total_return_direct = float(bench_eq.iloc[-1] - 1) if len(bench_eq) > 0 else bm_total_return\nbench_cagr_direct = float(bench_eq.iloc[-1] ** (1.0 / bench_n_years) - 1) if bench_n_years > 0 else bm_cagr\nbench_rolling_max = bench_eq.cummax()\nbench_dd = bench_eq / bench_rolling_max - 1\nbench_max_dd_direct = float(bench_dd.min()) if len(bench_dd) > 0 else bm_max_dd\n\n# Use strategy's internally computed benchmark metrics (same period alignment)\n# but cross-check with direct Alpaca fetch\nprint(f\"Strategy bm_cagr={bm_cagr:.4f}, direct bench_cagr={bench_cagr_direct:.4f}\", file=sys.stderr)\n\n# \u2500\u2500 Summary output \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nprint(f\"\\nBacktest: {backtest_start} \u2192 {backtest_end}\", file=sys.stderr)\nprint(f\"CAGR: {cagr:.4f}  |  BM CAGR: {bm_cagr:.4f}\", file=sys.stderr)\nprint(f\"Sharpe: {sharpe:.4f}  |  Sortino: {sortino:.4f}\", file=sys.stderr)\nprint(f\"Max DD: {max_dd:.4f}  |  BM Max DD: {bm_max_dd:.4f}\", file=sys.stderr)\nprint(f\"Total Trades: {total_trades}  |  Win Rate: {win_rate:.4f}\", file=sys.stderr)\nprint(f\"Alpha: {alpha:.4f}  |  IR: {information_ratio:.4f}\", file=sys.stderr)\n\nresult = {\n    \"backtest_start\": backtest_start,\n    \"backtest_end\": backtest_end,\n    \"cagr\": round(cagr, 6),\n    \"total_return\": round(total_return, 6),\n    \"volatility\": round(vol, 6),\n    \"sharpe_ratio\": round(sharpe, 6),\n    \"sortino_ratio\": round(sortino, 6),\n    \"calmar_ratio\": round(calmar, 6),\n    \"max_drawdown\": round(max_dd, 6),\n    \"max_drawdown_duration\": int(max_dd_duration),\n    \"total_trades\": int(total_trades),\n    \"win_rate\": round(win_rate, 6),\n    \"avg_win\": round(avg_win, 6),\n    \"avg_loss\": round(avg_loss, 6),\n    \"profit_factor\": round(profit_factor, 6),\n    \"expectancy\": round(expectancy, 6),\n    \"benchmark_cagr\": round(bm_cagr, 6),\n    \"benchmark_max_drawdown\": round(bm_max_dd, 6),\n    \"benchmark_total_return\": round(bm_total_return, 6),\n    \"alpha\": round(alpha, 6),\n    \"information_ratio\": round(information_ratio, 6),\n    \"excess_return\": round(excess_return, 6),\n    \"up_capture\": round(up_capture, 6),\n    \"down_capture\": round(down_capture, 6),\n}\n\nprint(json.dumps(result))",
      "stdout": "{\"backtest_start\": \"2021-06-16\", \"backtest_end\": \"2026-02-20\", \"cagr\": 0.036215, \"total_return\": 0.180592, \"volatility\": 0.085352, \"sharpe_ratio\": -0.009076, \"sortino_ratio\": -0.007878, \"calmar_ratio\": 0.230654, \"max_drawdown\": -0.157011, \"max_drawdown_duration\": 931, \"total_trades\": 8, \"win_rate\": 0.375, \"avg_win\": 0.078012, \"avg_loss\": -0.013296, \"profit_factor\": 3.520291, \"expectancy\": 0.020944, \"benchmark_cagr\": 0.125261, \"benchmark_max_drawdown\": -0.24512, \"benchmark_total_return\": 0.734528, \"alpha\": -0.025191, \"information_ratio\": -0.633039, \"excess_return\": -0.089045, \"up_capture\": 0.347858, \"down_capture\": 0.355546}\n",
      "stderr": "Fetching price data for SPY from Alpaca...\nALPACA_FETCH_OK timeframe=1Day rows=1401\nSaved canonical price data to __internal_price_data.csv (1401 rows)\nLoading yield curve data from T10Y2Y_spread.csv...\n  Loaded 12426 FRED observations from local file.\nBacktest period: 2021-06-16 \\u2192 2026-02-20 (1176 days)\nFetching benchmark (buy-and-hold SPY) from Alpaca...\nALPACA_FETCH_OK timeframe=1Day rows=1176\nStrategy bm_cagr=0.1253, direct bench_cagr=0.1267\n\nBacktest: 2021-06-16 \\u2192 2026-02-20\nCAGR: 0.0362  |  BM CAGR: 0.1253\nSharpe: -0.0091  |  Sortino: -0.0079\nMax DD: -0.1570  |  BM Max DD: -0.2451\nTotal Trades: 8  |  Win Rate: 0.3750\nAlpha: -0.0252  |  IR: -0.6330\n",
      "returncode": 0,
      "review_verdict": "success",
      "review_feedback": "",
      "review_message": "",
      "latency_ms": 67921
    }
  ]
}